# You can add new model configurations here with the following params:
# +------------------+------------------------+-----------------------------------+------------------------------------------------------------------------------+
# | param \ provider | litellm                | watsonx                           | openai (native, default setting)                                             |
# +------------------+------------------------+-----------------------------------+------------------------------------------------------------------------------+
# | model_name       | openai/gpt-4o          | meta-llama/llama-3-3-70b-instruct | gpt-4o                                                                       |
# +------------------+------------------------+-----------------------------------+------------------------------------------------------------------------------+
# | url              | <not set>              | https://us-south.ml.cloud.ibm.com | âœ—                                                                            |
# +------------------+------------------------+-----------------------------------+------------------------------------------------------------------------------+
# | api_key          | $OPENAI_API_KEY        | $WATSONX_API_KEY                  | $OPENAI_API_KEY                                                              |
# +------------------+------------------------+-----------------------------------+------------------------------------------------------------------------------+
# | seed             | x                      | <not set>                         | <not set>                                                                    |
# +------------------+------------------------+-----------------------------------+------------------------------------------------------------------------------+
# | top_p            | 0.95                   | 0.95                              | 0.95                                                                         |
# |                  |                        |                                   | Reasoning models (o1, o3) and newer models (gpt-5) don't support top_p       |
# +------------------+------------------------+-----------------------------------+------------------------------------------------------------------------------+
# | temperature      | 0.0                    | 0.0                               | 0.0                                                                          |
# |                  |                        |                                   | Reasoning models (o1, o3) and newer models (gpt-5) don't support temperature |
# +------------------+------------------------+-----------------------------------+------------------------------------------------------------------------------+
# | max_tokens       | <not set>              | <not set>                         | <not set>                                                                    |
# +------------------+------------------------+-----------------------------------+------------------------------------------------------------------------------+
# | project_id       | x                      | $WX_PROJECT_ID                    | x                                                                            |
# +------------------+------------------------+-----------------------------------+------------------------------------------------------------------------------+
# | azure_version    | $AZURE_API_VERSION     | x                                 | x                                                                            |
# |                  | Only for Azure backend |                                   |                                                                              |
# +------------------+------------------------+-----------------------------------+------------------------------------------------------------------------------+
# | - x means the provider backend does not support the param.                                                                                                   |
# | - <not set> means the param is not set and passed into the backend by default.                                                                               |
# | - Other values mean the default values if you don't overwrite below.                                                                                         |
# +--------------------------------------------------------------------------------------------------------------------------------------------------------------+

"gpt-4o":
  provider: "openai"
  model_name: "gpt-4o"
  api_key: "$OPENAI_API_KEY"
  top_p: 0.95
  temperature: 0.0

"gemini-2.5-pro":
  provider: "litellm"
  model_name: "gemini/gemini-2.5-pro"
  api_key: "$GEMINI_API_KEY"
  temperature: 0.0
  top_p: 0.95

"claude-sonnet-4":
  provider: "litellm"
  model_name: "anthropic/claude-sonnet-4-20250514"
  api_key: "$ANTHROPIC_API_KEY"
  temperature: 0.0
  top_p: 0.95

"moonshot":
  provider: "litellm"
  model_name: "moonshot/moonshot"
  api_key: "$MOONSHOT_API_KEY"
  temperature: 0.0
  top_p: 0.95

"watsonx-llama":
  provider: "watsonx"
  model_name: "meta-llama/llama-3-3-70b-instruct"
  api_key: "$WATSONX_API_KEY"
  url: "https://us-south.ml.cloud.ibm.com"
  wx_project_id: "$WX_PROJECT_ID"

"glm-4":
  provider: "litellm"
  model_name: "openai/glm-4" # this should use openai/xxx
  api_key: "$GLM_API_KEY"
  temperature: 0.0
  top_p: 0.95
  url: "https://open.bigmodel.cn/api/paas/v4/"

"azure-openai-gpt-4o":
  provider: "litellm"
  model_name: "azure/gpt-4o"
  api_key: "$AZURE_API_KEY"
  url: "$AZURE_API_BASE"